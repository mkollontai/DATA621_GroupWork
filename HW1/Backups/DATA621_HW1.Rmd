---
title: "DATA621 HW1"
author: "Misha Kollontai, Matthew Baker, Erinda Budo, Subhalaxmi Rout, Don Padmaperuma"
date: "9/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Data Exploration

```{r}
library(tidyverse)
MB_train <- read.csv("moneyball-training-data.csv")
```
Let's look at all of the metrics in order to evaluate the presence of outliers and quality of the data overall. 

```{r echo=FALSE}
ggplot(stack(MB_train[,-1]), aes(x = ind, y = values)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)
        )
```

```{r}
summary(MB_train)

```
Few more descriptive statistics of MB_train data.The descriptive statistics below shows the the mean, mode, **standard deviation**, minimum and maximum of each variable in the dataset.  

```{r}
library(pastecs)
stat.desc(MB_train, basic = F)
```

Hits Allowed (TEAM_PITCHING_H) and Strikeouts by Pitchers (TEAM_PITCHING_SO) clearly needs looking at. 

Let's take a look at  the number of strikeouts a team pitching staff has achieved in a given season. First, let's calculate the maximum number strikeouts a team can achieve per season assuming 162 games. This would require 3 strikeouts every 9 innings.

The record number of strikeouts by a pitching staff in a season is 1,687 by the Houston Astros in 2018 (this datapoint is not included here since the data only covers up to 2006). Since some of the data is extrapolated to assume a 162 game season, it's possible some earlier seasons may equate to more, so let's use 2000 as a max possible value. 

```{r Strikeouts by Pitchers}
Max_SO <- 162*9*3 #This assumes a season in which every out was a strikeout (obviously never happened)

library(ggplot2)
a <- ggplot(data = MB_train, aes(x = INDEX, y = TEAM_PITCHING_SO)) + geom_point()
a + geom_hline(yintercept=Max_SO, linetype = 'dashed') + 
  geom_hline(yintercept=2000, linetype = 'dashed', color='red')
```

According to [MLB.com](http://mlb.mlb.com/mlb/history/rare_feats/index.jsp?feature=most_hits_game) the most hits allowed in a game was 33. Assuming a 162 game seaosn, the highest number of hits allowed in a season possible would be $162*33 = 5346$ hits. Anything above this is impossible.

```{r Hits by Pitchers}
most_hits <- 162*33 

library(ggplot2)
a <- ggplot(data = MB_train, aes(x = INDEX, y = TEAM_PITCHING_H)) + geom_point()
a + geom_hline(yintercept=most_hits, linetype = 'dashed', color='red')
```

Based on the graph above, it looks like we are potentially leaving a large amount of erroneous data in the set, but we have no factual basis to remove it on. 

To get a closer look at the data, here we have a boxplot for *TARGET_WINS* variable and small multiples plot for other variables. 

```{r}
boxplot(MB_train$TARGET_WINS, xlab = "Target Wins")
```
```{r}
par(mfrow=c(3,5))

x <- c(2:16)
for (val in x) {
  boxplot(MB_train[,val], xlab=names(MB_train[val]))$out
}
```
Another look at the variables. Being able to examine Skewness and outliers of the data will help us to chose the model. This is important as some models will require transformation of data.

```{r}
library(reshape)
par(mfrow = c(3,3))

datasub = melt(MB_train)
ggplot(datasub, aes(x=value)) + 
  geom_density(fill = 'blue') + facet_wrap(~variable, scales = 'free')
```

### Relationship and correlation

Relationship of TARTGET_WINS vs. All other variables

```{r}
par(mfrow=c(3,5))

x <- c(2:16)
for (val in x) {
plot(MB_train[,val],MB_train$TARGET_WINS, xlab=names(MB_train[val]))
}
```
```{r}
par(mfrow=c(1,1))

cor(MB_train, use = "complete.obs")[,1]
```

```{r}
library(corrplot)
corr<- round(cor(MB_train[-1], use="pairwise.complete.obs", method = "pearson"),1)
corrplot(corr, method = "color", 
         type = "upper", order = "original", number.cex = .7,
         addCoef.col = "black", # Add coefficient of correlation
         tl.col = "black", tl.srt = 90, # Text label color and rotation
                  # hide correlation coefficient on the principal diagonal
         diag = TRUE)
```

## Data Preparation

We can clearly see that there is a fair amount of outliers in our data. To begin, let's simply remove these rows of data since we can't have faith in the rest of the data associated with the measurement. We can also remove the rows associated with other clearly erroneous data:

* No team has ever hit 0 home runs in a season according to [baseball-almanac1](https://www.baseball-almanac.com/recbooks/rb_hr7.shtml), so remove rows that claim such a season.

* No team has ever had 0 hitter strikeouts in a season according to [baseball-almanac2](https://www.baseball-almanac.com/recbooks/rb_strike2.shtml), so remove rows that claim such a season.

* According to [this article](http://research.sabr.org/journals/pitchers-giving-up-home-runs#:~:text=The%20fewest%20home%20runs%20given,more%20productive%20home%20run%20year.) "The fewest home runs given up by a pitching staff in one season was the four relinquished by the marvelous mound corps of the 1902 Pittsburgh Pirates over a 140-game schedule.

* Trusting the [research of user BowlOfRed](https://sports.stackexchange.com/questions/16246/what-is-the-mlb-record-for-most-errors-by-one-team-in-one-season-during-the-mode) the highest number of errors by a team in a season is Washington in 1886 commiting 867 errors in 122 games. If we extrapolate that number to 162 games we can cut out the false datapoints here as well. 


```{r clean data from outliers}
max_errors <- 867/122*162
MB_train_clean <- MB_train[!(MB_train$TEAM_PITCHING_SO > 2000),]
MB_train_clean <- MB_train_clean[!(MB_train_clean$TEAM_BATTING_HR == 0),]
MB_train_clean <- MB_train_clean[!(MB_train_clean$TEAM_BATTING_SO == 0),]
MB_train_clean <- MB_train_clean[!(MB_train_clean$TEAM_PITCHING_HR < 4),]
MB_train_clean <- MB_train_clean[!(MB_train_clean$TEAM_PITCHING_H > most_hits),]
MB_train_clean <- MB_train_clean[!(MB_train_clean$TEAM_FIELDING_E > max_errors),]

```


```{r echo=FALSE}
ggplot(stack(MB_train_clean[,-1]), aes(x = ind, y = values)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  ylim(0,2500)

```

We can see that a large amount of datapoints are missing (4550 according to the warning). Let's replace the NA's with the mean value for each column. 

```{r}
for(i in 1:ncol(MB_train_clean)){
  MB_train_clean[is.na(MB_train_clean[,i]), i] <- mean(MB_train_clean[,i], na.rm = TRUE)
}

```

```{r echo=FALSE}
ggplot(stack(MB_train_clean[,-1]), aes(x = ind, y = values)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  ylim(0,2500)

```

Take a look at the summary of cleaned data. As you can see there are no more NA data in the dataset.   

```{r}
summary(MB_train_clean)
```
```{r}
par(mfrow = c(3,3))

datasub = melt(MB_train_clean)
ggplot(datasub, aes(x=value)) + 
  geom_density(fill = 'blue') + facet_wrap(~variable, scales = 'free')
```

To begin let's take a look at the model using all of the original data. This model includes all outliers that we looked over in the section above. 

```{r}
mod0 <- lm(TARGET_WINS ~ . - INDEX, data= MB_train)
summary(mod0)
```

Next let's create a model that removes the outliers and patently false values identified in the previous section as well as the missing datapoints. 

```{r}
mod1 <- lm(TARGET_WINS ~ . - INDEX, data= MB_train_clean)
summary(mod1)
```

We can immediately see how much more statistically significant each of our predictors are - nearly every single p-value is noticeably lower than it was in the initial model. This suggests that the data in this model is more likely to have a relationship with our target variable. 

Based on the summary above, we can see that the Baserun CS and Batting HBP stats provide the least value, so we can start improving our model by removing them:


```{r}
mod2 <- lm(TARGET_WINS ~ . - INDEX - TEAM_BASERUN_CS - TEAM_BATTING_HBP, data= MB_train_clean)
summary(mod2)
```

The following stats we can look into removing are the Batting H, Batting 2B and Pitching HR stats. 

```{r}
mod3 <- lm(TARGET_WINS ~ . - INDEX - TEAM_BASERUN_CS - TEAM_BATTING_HBP - TEAM_BATTING_H    - TEAM_BATTING_2B -  TEAM_PITCHING_HR, data= MB_train_clean)
summary(mod3)
```

```{r}
plot(mod3)
```

Looking at the plots above we can see a fairly linear Q-Q plot outside of the extreme values. The standardized residuals also appear to be fairly randomly distributed, another good sign. 

Oddly enough, the strikeout metrics (along with the Fielding DP) have the highest p-values, so we can further simplify our model by removing them and see how that impacts our model.


```{r}
mod4 <- lm(TARGET_WINS ~ . - INDEX - TEAM_BASERUN_CS - TEAM_BATTING_HBP - TEAM_BATTING_H    - TEAM_BATTING_2B -  TEAM_PITCHING_HR - TEAM_BATTING_SO - TEAM_PITCHING_SO - TEAM_FIELDING_DP, data= MB_train_clean)
summary(mod4)
```

Let's attempt a prediction using the latest model. To do so we must take a subset of our test dataset that includes only the columns we choose to use in the prediction. 

```{r}
MB_test<- read.csv("moneyball-evaluation-data.csv")
```

Let's identify all of the rows containing obvious outliers in the data:

```{r}
Out <- function(x){
  if (x[2] > most_hits * 1.25 | x[11] > most_hits*1.25) { 
    return (1)
  } else if (x[7] > Max_SO | x[14] > Max_SO) {
    return (1)
  } else if (x[15] > max_errors){
    return (1)
  } else {
    return (0)
  }
}
```

```{r}
#First we replace NAs with the median values
for(i in 1:ncol(MB_test)){
  MB_test[is.na(MB_test[,i]), i] <- median(MB_test[,i], na.rm = TRUE)
}

MB_test$Outliers <- apply(MB_test, 1, FUN = Out) 
MB_test$P_Wins <- round(predict(mod4,  newdata = MB_test),0)
MB_test[c('INDEX','P_Wins')]
```